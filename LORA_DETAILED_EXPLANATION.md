# LoRA (Low-Rank Adaptation) μƒμ„Έ μ„¤λ…

## π“ λ©μ°¨
1. [LoRA κΈ°λ³Έ μ›λ¦¬](#lora-κΈ°λ³Έ-μ›λ¦¬)
2. [μν•™μ  λ°°κ²½](#μν•™μ -λ°°κ²½)
3. [μ½”λ“ κµ¬ν„ λ¶„μ„](#μ½”λ“-κµ¬ν„-λ¶„μ„)
4. [νλΌλ―Έν„° μ„¤λ…](#νλΌλ―Έν„°-μ„¤λ…)
5. [μ‹¤μ  λ™μ‘ μμ‹](#μ‹¤μ -λ™μ‘-μμ‹)

---

## π― LoRA κΈ°λ³Έ μ›λ¦¬

### λ¬Έμ : Full Fine-tuningμ ν•κ³„

μΌλ°μ μΈ Fine-tuning:
```
Original Weight: W β β„^(dΓ—k)  (μ: 768Γ—768)
Fine-tuned:     W' = W + Ξ”W
```

**λ¬Έμ μ **:
- Ξ”Wλ„ Wμ™€ κ°™μ€ ν¬κΈ° (768Γ—768 = 589,824 νλΌλ―Έν„°)
- λ¨λ“  νλΌλ―Έν„°λ¥Ό μ €μ¥/μ—…λ°μ΄νΈν•΄μ•Ό ν•¨
- λ©”λ¨λ¦¬ λ° μ €μ¥ κ³µκ°„ λΉ„ν¨μ¨μ 

---

### ν•΄κ²°: Low-Rank Decomposition

LoRAμ ν•µμ‹¬ μ•„μ΄λ””μ–΄:
```
Ξ”Wλ¥Ό λ‘ κ°μ μ‘μ€ ν–‰λ ¬λ΅ λ¶„ν•΄!

Ξ”W = B Γ— A

μ—¬κΈ°μ„:
- A β β„^(rΓ—k)  (r << d, r << k)
- B β β„^(dΓ—r)
- r: rank (λ³΄ν†µ 4, 8, 16 λ“±)
```

**μμ‹** (d=768, k=768, r=8):
```
κΈ°μ΅΄ λ°©μ‹:
Ξ”W: 768Γ—768 = 589,824 νλΌλ―Έν„°

LoRA λ°©μ‹:
A: 8Γ—768 = 6,144 νλΌλ―Έν„°
B: 768Γ—8 = 6,144 νλΌλ―Έν„°
ν•©κ³„: 12,288 νλΌλ―Έν„° (98% μ μ•½!)
```

---

## π“ μν•™μ  λ°°κ²½

### 1. Forward Pass

**μ›λ λ μ΄μ–΄**:
```
h = WΒ·x
```

**LoRA μ μ© ν›„**:
```
h = WΒ·x + Ξ”WΒ·x
  = WΒ·x + (BΒ·A)Β·x
  = WΒ·x + BΒ·(AΒ·x)
```

**κµ¬ν„**:
```python
# μ›λ κ°€μ¤‘μΉλ” λ™κ²° (frozen)
W.requires_grad = False

# LoRA ν–‰λ ¬λ§ ν•™μµ
A.requires_grad = True
B.requires_grad = True

# Forward
output = W @ x + (B @ (A @ x)) * (alpha / r)
```

---

### 2. Scaling Factor (alpha / r)

```python
scaling = lora_alpha / r
output = W @ x + (B @ A @ x) * scaling
```

**μ΄μ **:
- `alpha`: ν•™μµλ¥  μ΅°μ • (λ³΄ν†µ rμ 2λ°°, μ: r=8μ΄λ©΄ alpha=16)
- `alpha / r`: LoRAμ μν–¥λ ¥ μ΅°μ 
- rankκ°€ μ»¤μ§μλ΅ μλ™μΌλ΅ μ¤μΌ€μΌ μ΅°μ •

**μμ‹**:
```
r=4, alpha=8  β†’ scaling=2.0
r=8, alpha=16 β†’ scaling=2.0
r=16, alpha=32 β†’ scaling=2.0
```

---

### 3. Initialization

**A ν–‰λ ¬**: Gaussian μ΄κΈ°ν™”
```python
A ~ N(0, ΟƒΒ²)  # μ •κ·λ¶„ν¬
```

**B ν–‰λ ¬**: Zero μ΄κΈ°ν™”
```python
B = 0
```

**μ΄μ **:
- μ΄κΈ°μ—λ” Ξ”W = BΒ·A = 0Β·A = 0
- ν•™μµ μ‹μ‘ μ‹ μ›λ λ¨λΈκ³Ό λ™μΌ
- μ•μ •μ μΈ ν•™μµ μ‹μ‘

---

## π’» μ½”λ“ κµ¬ν„ λ¶„μ„

### 1. LoRA Config μƒμ„± (Line 113-121)

```python
lora_config = {
    "r": 8,                              # Rank: LoRA ν–‰λ ¬μ μ°¨μ›
    "lora_alpha": 16,                    # Scaling factor
    "lora_dropout": 0.05,                # Dropout λΉ„μ¨
    "bias": "none",                      # Bias ν•™μµ μ—¬λ¶€
    "task_type": TaskType.CAUSAL_LM,    # νƒμ¤ν¬ νƒ€μ…
    "target_modules": ["c_attn", "c_proj"]  # μ μ©ν•  λ¨λ“
}
```

**κ° νλΌλ―Έν„° μλ―Έ**:

#### `r` (rank)
```
μ‘μ„μλ΅: νλΌλ―Έν„° μ μ, ν‘ν„λ ¥ λ‚®μ
ν΄μλ΅:   νλΌλ―Έν„° λ§μ, ν‘ν„λ ¥ λ†’μ

κ¶μ¥κ°’:
- κ°„λ‹¨ν• νƒμ¤ν¬: r=4
- μΌλ°μ : r=8
- λ³µμ΅ν• νƒμ¤ν¬: r=16, 32
```

#### `lora_alpha`
```
scaling = alpha / r

alphaκ°€ ν΄μλ΅: LoRAμ μν–¥λ ¥ μ¦κ°€
λ³΄ν†µ rμ 2λ°°λ΅ μ„¤μ • (r=8 β†’ alpha=16)
```

#### `target_modules`
```python
# GPT-2μ κ²½μ°
"c_attn":  Query, Key, Value ν–‰λ ¬ (Attention)
"c_proj":  Attention μ¶λ ¥ projection

# λ‹¤λ¥Έ λ¨λΈ μμ‹
"q_proj", "k_proj", "v_proj", "o_proj"  # LLaMA
"query", "key", "value"                   # BERT
```

---

### 2. LoRA Config κ°μ²΄ μƒμ„± (Line 143)

```python
from peft import LoraConfig

peft_config = LoraConfig(**lora_config)
```

**λ‚΄λ¶€ λ™μ‘**:
```python
class LoraConfig:
    def __init__(self, r, lora_alpha, target_modules, ...):
        self.r = r
        self.lora_alpha = lora_alpha
        self.target_modules = target_modules
        # ... μ„¤μ • μ €μ¥
```

---

### 3. LoRA μ μ© (Line 146)

```python
from peft import get_peft_model

model = get_peft_model(model, peft_config)
```

**λ‚΄λ¶€ λ™μ‘ (κ°„λµν™”)**:
```python
def get_peft_model(model, config):
    # 1. λ¨λΈμ λ¨λ“  λ μ΄μ–΄ μν
    for name, module in model.named_modules():
        
        # 2. target_modulesμ— ν•΄λ‹Ήν•λ” λ μ΄μ–΄ μ°ΎκΈ°
        if any(target in name for target in config.target_modules):
            
            # 3. μ›λ κ°€μ¤‘μΉ λ™κ²°
            module.weight.requires_grad = False
            
            # 4. LoRA ν–‰λ ¬ μƒμ„±
            in_features = module.weight.shape[1]
            out_features = module.weight.shape[0]
            
            # A ν–‰λ ¬: (r, in_features)
            lora_A = nn.Parameter(torch.randn(config.r, in_features))
            
            # B ν–‰λ ¬: (out_features, r)
            lora_B = nn.Parameter(torch.zeros(out_features, config.r))
            
            # 5. LoRA λ μ΄μ–΄λ΅ κµμ²΄
            module.lora_A = lora_A
            module.lora_B = lora_B
            module.scaling = config.lora_alpha / config.r
            
            # 6. Forward ν•¨μ μμ •
            original_forward = module.forward
            
            def new_forward(x):
                # μ›λ μ¶λ ¥
                output = original_forward(x)
                
                # LoRA μ¶λ ¥ μ¶”κ°€
                lora_output = (x @ lora_A.T) @ lora_B.T * scaling
                
                return output + lora_output
            
            module.forward = new_forward
    
    return model
```

---

## π” μ‹¤μ  λ™μ‘ μμ‹

### GPT-2 Smallμ κ²½μ°

**μ›λ λ¨λΈ**:
```
GPT-2 Small: 124M νλΌλ―Έν„°
- 12 Transformer layers
- κ° layerμ— c_attn, c_proj μ΅΄μ¬
```

**LoRA μ μ© (r=8)**:

#### 1. c_attn λ μ΄μ–΄
```
μ›λ κ°€μ¤‘μΉ: W_attn β β„^(2304Γ—768)
- Query, Key, Valueλ¥Ό ν•λ²μ— κ³„μ‚°
- νλΌλ―Έν„°: 2304 Γ— 768 = 1,769,472

LoRA μ¶”κ°€:
- A_attn β β„^(8Γ—768)   = 6,144 νλΌλ―Έν„°
- B_attn β β„^(2304Γ—8)  = 18,432 νλΌλ―Έν„°
- ν•©κ³„: 24,576 νλΌλ―Έν„° (1.4%)
```

#### 2. c_proj λ μ΄μ–΄
```
μ›λ κ°€μ¤‘μΉ: W_proj β β„^(768Γ—768)
- Attention μ¶λ ¥ projection
- νλΌλ―Έν„°: 768 Γ— 768 = 589,824

LoRA μ¶”κ°€:
- A_proj β β„^(8Γ—768)  = 6,144 νλΌλ―Έν„°
- B_proj β β„^(768Γ—8)  = 6,144 νλΌλ―Έν„°
- ν•©κ³„: 12,288 νλΌλ―Έν„° (2.1%)
```

#### 3. μ „μ²΄ λ¨λΈ
```
12 layers Γ— (c_attn + c_proj)
= 12 Γ— (24,576 + 12,288)
= 12 Γ— 36,864
= 442,368 νλΌλ―Έν„°

μ‹¤μ  μΈ΅μ •: 811,008 νλΌλ―Έν„°
(Dropout, Bias λ“± μ¶”κ°€ νλΌλ―Έν„° ν¬ν•¨)

λΉ„μ¨: 811,008 / 124,439,808 = 0.65%
```

---

## π“ νλΌλ―Έν„° κ³„μ‚° μμ‹

### Rankμ— λ”°λ¥Έ νλΌλ―Έν„° μ

**c_attn (2304Γ—768)**:
```
r=4:  (4Γ—768) + (2304Γ—4)  = 3,072 + 9,216  = 12,288
r=8:  (8Γ—768) + (2304Γ—8)  = 6,144 + 18,432 = 24,576
r=16: (16Γ—768) + (2304Γ—16) = 12,288 + 36,864 = 49,152
r=32: (32Γ—768) + (2304Γ—32) = 24,576 + 73,728 = 98,304
```

**c_proj (768Γ—768)**:
```
r=4:  (4Γ—768) + (768Γ—4)  = 3,072 + 3,072  = 6,144
r=8:  (8Γ—768) + (768Γ—8)  = 6,144 + 6,144  = 12,288
r=16: (16Γ—768) + (768Γ—16) = 12,288 + 12,288 = 24,576
r=32: (32Γ—768) + (768Γ—32) = 24,576 + 24,576 = 49,152
```

---

## π― LoRAμ μ¥μ 

### 1. λ©”λ¨λ¦¬ ν¨μ¨μ„±
```
Full Fine-tuning: 124M νλΌλ―Έν„° ν•™μµ
LoRA (r=8):      0.8M νλΌλ―Έν„° ν•™μµ (99.4% μ μ•½)
```

### 2. μ €μ¥ κ³µκ°„ ν¨μ¨μ„±
```
Full model checkpoint: ~500MB
LoRA checkpoint:       ~9.4MB (98% μ μ•½)
```

### 3. ν•™μµ μ†λ„
```
Gradient κ³„μ‚°: 0.65% νλΌλ―Έν„°λ§
Optimizer state: 0.65% νλΌλ―Έν„°λ§
β†’ λ©”λ¨λ¦¬ λ° κ³„μ‚°λ‰ λ€ν­ κ°μ†
```

### 4. λ‹¤μ¤‘ νƒμ¤ν¬ μ§€μ›
```
Base model: 1κ° (500MB)
Task 1 LoRA: 9.4MB
Task 2 LoRA: 9.4MB
Task 3 LoRA: 9.4MB
...
β†’ μ—¬λ¬ νƒμ¤ν¬λ¥Ό ν¨μ¨μ μΌλ΅ κ΄€λ¦¬
```

---

## π’΅ ν•µμ‹¬ μ”μ•½

### LoRAμ ν•µμ‹¬ μ•„μ΄λ””μ–΄
```
1. ν° ν–‰λ ¬ Ξ”Wλ¥Ό λ‘ κ°μ μ‘μ€ ν–‰λ ¬ B, Aλ΅ λ¶„ν•΄
2. Ξ”W = B Γ— A (Low-Rank Decomposition)
3. μ›λ κ°€μ¤‘μΉ Wλ” λ™κ²°, Bμ™€ Aλ§ ν•™μµ
4. Forward: output = WΒ·x + BΒ·(AΒ·x) Γ— (alpha/r)
```

### νλΌλ―Έν„° μ„¤μ • κ°€μ΄λ“
```
r (rank):
- κ°„λ‹¨ν• νƒμ¤ν¬: 4
- μΌλ°μ : 8
- λ³µμ΅ν• νƒμ¤ν¬: 16-32

lora_alpha:
- λ³΄ν†µ rμ 2λ°° (r=8 β†’ alpha=16)

target_modules:
- Attention λ μ΄μ–΄ (q, k, v, o)
- MLP λ μ΄μ–΄ (μ„ νƒμ )
```

### μ‹¤μ  ν¨κ³Ό (μ°λ¦¬ ν”„λ΅μ νΈ)
```
λ¨λΈ: GPT-2 Small (124M)
LoRA: r=8, alpha=16
κ²°κ³Ό:
- ν•™μµ νλΌλ―Έν„°: 0.65% (811K)
- μ²΄ν¬ν¬μΈνΈ: 9.4MB
- Perplexity: 9.08 β†’ 1.05 (88% κ°μ†)
- ν•™μµ μ‹κ°„: 27λ¶„ (20 epochs)
```

---

## π”¬ μ¶”κ°€ μλ£

### PEFT λΌμ΄λΈλ¬λ¦¬ λ‚΄λ¶€ κµ¬μ΅°
```python
# peft/tuners/lora/layer.py (κ°„λµν™”)

class LoraLayer:
    def __init__(self, r, lora_alpha, ...):
        self.r = r
        self.lora_alpha = lora_alpha
        self.scaling = lora_alpha / r
        
        # LoRA ν–‰λ ¬ μ΄κΈ°ν™”
        self.lora_A = nn.Parameter(torch.randn(r, in_features))
        self.lora_B = nn.Parameter(torch.zeros(out_features, r))
    
    def forward(self, x):
        # μ›λ μ¶λ ¥
        result = self.base_layer(x)
        
        # LoRA μ¶λ ¥ μ¶”κ°€
        lora_result = (x @ self.lora_A.T) @ self.lora_B.T
        result = result + lora_result * self.scaling
        
        return result
```

### μ°Έκ³  λ…Όλ¬Έ
- **LoRA: Low-Rank Adaptation of Large Language Models**
  - Authors: Edward Hu et al. (Microsoft)
  - Year: 2021
  - Link: https://arxiv.org/abs/2106.09685

---

μ΄μ  LoRAμ μ›λ¦¬μ™€ κµ¬ν„μ„ μ™„μ „ν μ΄ν•΄ν•μ…¨μ„ κ²ƒμ…λ‹λ‹¤! π€
