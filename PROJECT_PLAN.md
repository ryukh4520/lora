# LoRA ν•™μµ λ°λ¨ ν”„λ΅μ νΈ μ„¤κ³„μ•

## π― ν”„λ΅μ νΈ κ°μ”
RTX 3070 (8GB VRAM) ν™κ²½μ—μ„ μ‘μ€ LLMμ„ LoRA(Low-Rank Adaptation)λ¥Ό ν†µν•΄ ν¨μ¨μ μΌλ΅ νμΈνλ‹ν•λ” λ°λ¨ ν”„λ΅μ νΈ

---

## π“‹ ν•λ“μ›¨μ–΄ μ μ•½μ‚¬ν•­ λ¶„μ„

### ν„μ¬ ν™κ²½
- **GPU**: RTX 3070
- **VRAM**: 8GB
- **μ μ•½μ‚¬ν•­**: 
  - λ€ν• λ¨λΈ(7B μ΄μƒ) μ „μ²΄ νμΈνλ‹ λ¶κ°€λ¥
  - λ°°μΉ μ‚¬μ΄μ¦ μ ν•
  - μ‹ν€€μ¤ κΈΈμ΄ μ ν• ν•„μ”

### μµμ ν™” μ „λµ
- LoRAλ¥Ό ν†µν• νλΌλ―Έν„° ν¨μ¨μ  ν•™μµ (ν•™μµ νλΌλ―Έν„° < 1%)
- 4-bit/8-bit μ–‘μν™” (QLoRA) ν™μ©
- Gradient Checkpointing ν™μ©
- μ‘μ€ λ¨λΈ μ„ νƒ (1B~3B νλΌλ―Έν„°)

---

## π—οΈ ν”„λ΅μ νΈ κµ¬μ΅°

```
lora/
β”β”€β”€ README.md                    # ν”„λ΅μ νΈ μ„¤λ…μ„
β”β”€β”€ requirements.txt             # μμ΅΄μ„± ν¨ν‚¤μ§€
β”β”€β”€ config/
β”‚   β”β”€β”€ model_config.yaml       # λ¨λΈ μ„¤μ •
β”‚   β””β”€β”€ training_config.yaml    # ν•™μµ μ„¤μ •
β”β”€β”€ data/
β”‚   β”β”€β”€ raw/                    # μ›λ³Έ λ°μ΄ν„°
β”‚   β”β”€β”€ processed/              # μ „μ²λ¦¬λ λ°μ΄ν„°
β”‚   β””β”€β”€ prepare_dataset.py      # λ°μ΄ν„° μ „μ²λ¦¬ μ¤ν¬λ¦½νΈ
β”β”€β”€ src/
β”‚   β”β”€β”€ __init__.py
β”‚   β”β”€β”€ model.py                # λ¨λΈ λ΅λ”© λ° LoRA μ„¤μ •
β”‚   β”β”€β”€ dataset.py              # λ°μ΄ν„°μ…‹ ν΄λμ¤
β”‚   β”β”€β”€ trainer.py              # ν•™μµ λ΅μ§
β”‚   β””β”€β”€ utils.py                # μ ν‹Έλ¦¬ν‹° ν•¨μ
β”β”€β”€ scripts/
β”‚   β”β”€β”€ train.py                # ν•™μµ μ‹¤ν–‰ μ¤ν¬λ¦½νΈ
β”‚   β”β”€β”€ inference.py            # μ¶”λ΅  ν…μ¤νΈ μ¤ν¬λ¦½νΈ
β”‚   β””β”€β”€ merge_lora.py           # LoRA κ°€μ¤‘μΉ λ³‘ν•© μ¤ν¬λ¦½νΈ
β”β”€β”€ notebooks/
β”‚   β””β”€β”€ demo.ipynb              # λ°λ¨ λ…ΈνΈλ¶
β”β”€β”€ outputs/
β”‚   β”β”€β”€ checkpoints/            # μ²΄ν¬ν¬μΈνΈ
β”‚   β”β”€β”€ logs/                   # ν•™μµ λ΅κ·Έ
β”‚   β””β”€β”€ merged_models/          # λ³‘ν•©λ λ¨λΈ
β””β”€β”€ tests/
    β””β”€β”€ test_model.py           # λ‹¨μ„ ν…μ¤νΈ
```

---

## π¤– μ¶”μ² λ¨λΈ μ„ νƒ

### Option 1: GPT-2 Small (124M) β­ μ¶”μ² (μ…λ¬Έμ©)
- **νλΌλ―Έν„°**: 124M
- **VRAM μ‚¬μ©λ‰**: ~2GB (LoRA + 8bit)
- **μ¥μ **: λΉ λ¥Έ ν•™μµ, μ•μ •μ , ν•κµ­μ–΄ ν† ν¬λ‚μ΄μ € μ»¤μ¤ν„°λ§μ΄μ§• κ°€λ¥
- **λ‹¨μ **: μ„±λ¥ μ ν•μ 
- **μμƒ ν•™μµ μ‹κ°„** (10K μƒν”, 3 epochs):
  - **μ΄ μ†μ” μ‹κ°„**: ~30-45λ¶„
  - **μ΄λ‹Ή μƒν” μ²λ¦¬**: ~10-12 samples/sec
  - **Epochλ‹Ή μ‹κ°„**: ~10-15λ¶„
  - **μ¶”μ² μ‚¬μ© μΌ€μ΄μ¤**: λΉ λ¥Έ ν”„λ΅ν† νƒ€μ΄ν•‘, LoRA κ°λ… ν•™μµ, μ‹¤ν—

### Option 2: Llama-2-1B / TinyLlama-1.1B β­β­ μ¶”μ²
- **νλΌλ―Έν„°**: 1.1B
- **VRAM μ‚¬μ©λ‰**: ~4-5GB (QLoRA + 4bit)
- **μ¥μ **: μµμ‹  μ•„ν‚¤ν…μ², μΆ‹μ€ μ„±λ¥
- **λ‹¨μ **: GPT-2λ³΄λ‹¤ λλ¦Ό
- **μμƒ ν•™μµ μ‹κ°„** (10K μƒν”, 3 epochs):
  - **μ΄ μ†μ” μ‹κ°„**: ~1.5-2μ‹κ°„
  - **μ΄λ‹Ή μƒν” μ²λ¦¬**: ~4-5 samples/sec
  - **Epochλ‹Ή μ‹κ°„**: ~30-40λ¶„
  - **μ¶”μ² μ‚¬μ© μΌ€μ΄μ¤**: μ‹¤μ©μ μΈ μ„±λ¥μ΄ ν•„μ”ν• ν”„λ΅μ νΈ, κ· ν•μ΅ν μ„ νƒ

### Option 3: Phi-2 (2.7B) β­β­β­ μµκ³  μ¶”μ²
- **νλΌλ―Έν„°**: 2.7B
- **VRAM μ‚¬μ©λ‰**: ~6-7GB (QLoRA + 4bit)
- **μ¥μ **: Microsoft κ°λ°, λ›°μ–΄λ‚ μ„±λ¥, 8GB VRAMμ—μ„ ν•™μµ κ°€λ¥
- **λ‹¨μ **: μƒλ€μ μΌλ΅ λ¬΄κ±°μ›€
- **μμƒ ν•™μµ μ‹κ°„** (10K μƒν”, 3 epochs):
  - **μ΄ μ†μ” μ‹κ°„**: ~2.5-3.5μ‹κ°„
  - **μ΄λ‹Ή μƒν” μ²λ¦¬**: ~2.5-3 samples/sec
  - **Epochλ‹Ή μ‹κ°„**: ~50-70λ¶„
  - **μ¶”μ² μ‚¬μ© μΌ€μ΄μ¤**: μµκ³  ν’μ§μ΄ ν•„μ”ν• ν”„λ΅λ•μ… ν™κ²½, λ³µμ΅ν• νƒμ¤ν¬

**μµμΆ… μ¶”μ²**: **Phi-2** (μ„±λ¥κ³Ό VRAM ν¨μ¨μ„±μ κ· ν•)

---

### π“ ν•™μµ μ‹κ°„ λΉ„κµν‘ (RTX 3070 κΈ°μ¤€)

| λ¨λΈ | νλΌλ―Έν„° | VRAM | 1 Epoch | 3 Epochs | Samples/sec | μ‹κ°„λ‹Ή μ²λ¦¬λ‰ |
|------|----------|------|---------|----------|-------------|---------------|
| **GPT-2 Small** | 124M | ~2GB | 10-15λ¶„ | 30-45λ¶„ | 10-12 | ~36K-43K |
| **TinyLlama-1.1B** | 1.1B | ~4-5GB | 30-40λ¶„ | 1.5-2μ‹κ°„ | 4-5 | ~14K-18K |
| **Phi-2** | 2.7B | ~6-7GB | 50-70λ¶„ | 2.5-3.5μ‹κ°„ | 2.5-3 | ~9K-11K |

**μ°Έκ³ μ‚¬ν•­**:
- μ„ μ‹κ°„μ€ `max_seq_length=512`, `batch_size=1`, `gradient_accumulation_steps=16` κΈ°μ¤€
- μ‹¤μ  μ‹κ°„μ€ λ°μ΄ν„° λ³µμ΅λ„, μ‹ν€€μ¤ κΈΈμ΄, μ‹μ¤ν… μƒνƒμ— λ”°λΌ Β±20% λ³€λ™ κ°€λ¥
- `max_seq_length`λ¥Ό 256μΌλ΅ μ¤„μ΄λ©΄ ν•™μµ μ‹κ°„ ~40% λ‹¨μ¶• κ°€λ¥
- `gradient_accumulation_steps`λ¥Ό 8λ΅ μ¤„μ΄λ©΄ ν•™μµ μ‹κ°„ ~20% λ‹¨μ¶• (λ‹¨, μ„±λ¥ μ €ν• κ°€λ¥)

---

### π― μƒν™©λ³„ λ¨λΈ μ„ νƒ κ°€μ΄λ“

#### λΉ λ¥Έ μ‹¤ν— λ° ν•™μµμ΄ λ©μ μ΄λΌλ©΄
β†’ **GPT-2 Small** (30-45λ¶„)
- LoRA κ°λ… μ΄ν•΄
- νμ΄ν”„λΌμΈ ν…μ¤νΈ
- ν•μ΄νΌνλΌλ―Έν„° μ‹¤ν—

#### ν•λ£¨ μ•μ— μ‹¤μ©μ μΈ κ²°κ³Όκ°€ ν•„μ”ν•λ‹¤λ©΄
β†’ **TinyLlama-1.1B** (1.5-2μ‹κ°„)
- μ—¬λ¬ λ² μ‹¤ν— κ°€λ¥ (ν•λ£¨ 4-5ν)
- κ΄μ°®μ€ μ„±λ¥
- VRAM μ—¬μ  μμ

#### μµκ³  ν’μ§μ κ²°κ³Όκ°€ ν•„μ”ν•κ³  μ‹κ°„ μ—¬μ κ°€ μλ‹¤λ©΄
β†’ **Phi-2** (2.5-3.5μ‹κ°„)
- λ°¤μƒ ν•™μµ κ°€λ¥
- ν”„λ΅λ•μ… λ λ²¨ ν’μ§
- λ³µμ΅ν• instruction following

#### λ€μ©λ‰ λ°μ΄ν„°μ…‹ (50K+ μƒν”)μ„ ν•™μµν•λ‹¤λ©΄
β†’ **GPT-2 Small** λλ” **TinyLlama-1.1B**
- Phi-2λ” 50K μƒν” κΈ°μ¤€ 12-17μ‹κ°„ μ†μ”
- μ‹¤μ©μ„± κ³ λ ¤ ν•„μ”

---

## π“ ν•™μµ λ°μ΄ν„°μ…‹ μ„ νƒ

### Option 1: ν•κµ­μ–΄ λ€ν™” λ°μ΄ν„°
- **λ°μ΄ν„°μ…‹**: AI Hub ν•κµ­μ–΄ λ€ν™” μ”μ•½, KoAlpaca
- **μ©λ„**: μ±—λ΄‡, λ€ν™”ν• AI

### Option 2: ν•κµ­μ–΄ μ§€μ‹μ‚¬ν•­ λ”°λ¥΄κΈ°
- **λ°μ΄ν„°μ…‹**: KoAlpaca, Korean Instruction Dataset
- **μ©λ„**: Instruction Following

### Option 3: μ»¤μ¤ν…€ λ„λ©”μΈ λ°μ΄ν„°
- **λ°μ΄ν„°μ…‹**: μ‚¬μ©μ μ •μ (μ: νΉμ • λ¶„μ•Ό QA)
- **μ©λ„**: νΉν™”λ μ‘μ—…

**λ°λ¨μ© μ¶”μ²**: **KoAlpaca** (ν•κµ­μ–΄ Instruction λ°μ΄ν„°, κ³µκ° λ°μ΄ν„°μ…‹)

---

## π”§ κΈ°μ  μ¤νƒ

### ν•µμ‹¬ λΌμ΄λΈλ¬λ¦¬
1. **transformers** (Hugging Face): λ¨λΈ λ΅λ”© λ° ν•™μµ
2. **peft** (Parameter-Efficient Fine-Tuning): LoRA κµ¬ν„
3. **bitsandbytes**: 4-bit/8-bit μ–‘μν™”
4. **accelerate**: λ¶„μ‚° ν•™μµ λ° μµμ ν™”
5. **datasets**: λ°μ΄ν„°μ…‹ λ΅λ”© λ° μ „μ²λ¦¬
6. **wandb** (μ„ νƒ): ν•™μµ λ¨λ‹ν„°λ§

### LoRA μ„¤μ • νλΌλ―Έν„°
```yaml
lora_r: 8                    # LoRA rank (λ‚®μ„μλ΅ νλΌλ―Έν„° μ μ)
lora_alpha: 16               # LoRA scaling factor
lora_dropout: 0.05           # Dropout λΉ„μ¨
target_modules:              # LoRA μ μ© λ μ΄μ–΄
  - q_proj
  - v_proj
  - k_proj
  - o_proj
```

### ν•™μµ ν•μ΄νΌνλΌλ―Έν„° (8GB VRAM μµμ ν™”)
```yaml
# λ¨λΈ λ΅λ”©
load_in_4bit: true           # 4-bit μ–‘μν™” (QLoRA)
bnb_4bit_compute_dtype: float16
bnb_4bit_quant_type: "nf4"

# ν•™μµ μ„¤μ •
batch_size: 1                # Gradient AccumulationμΌλ΅ λ³΄μ™„
gradient_accumulation_steps: 16  # μ‹¤μ§μ  λ°°μΉ μ‚¬μ΄μ¦ = 16
max_seq_length: 512          # μ‹ν€€μ¤ κΈΈμ΄ (λ©”λ¨λ¦¬ μ μ•½)
learning_rate: 2e-4
num_epochs: 3
warmup_steps: 100
gradient_checkpointing: true # λ©”λ¨λ¦¬ μ μ•½

# μµμ ν™”
optim: "paged_adamw_8bit"    # λ©”λ¨λ¦¬ ν¨μ¨μ  μµν‹°λ§μ΄μ €
fp16: true                   # Mixed Precision Training
```

---

## π“ λ‹¨κ³„λ³„ κµ¬ν„ κ³„ν

### Phase 1: ν™κ²½ μ„¤μ • λ° κΈ°λ³Έ κµ¬μ΅° (30λ¶„)
1. ν”„λ΅μ νΈ λ””λ ‰ν† λ¦¬ μƒμ„±
2. `requirements.txt` μ‘μ„±
3. κ°€μƒν™κ²½ μ„¤μ • λ° ν¨ν‚¤μ§€ μ„¤μΉ
4. κΈ°λ³Έ μ„¤μ • νμΌ μ‘μ„±

**μ‚°μ¶λ¬Ό**:
- ν”„λ΅μ νΈ ν΄λ” κµ¬μ΅°
- `requirements.txt`
- `config/model_config.yaml`
- `config/training_config.yaml`

---

### Phase 2: λ°μ΄ν„° μ¤€λΉ„ (30λ¶„)
1. μƒν” λ°μ΄ν„°μ…‹ λ‹¤μ΄λ΅λ“ (KoAlpaca λλ” μ»¤μ¤ν…€)
2. λ°μ΄ν„° μ „μ²λ¦¬ μ¤ν¬λ¦½νΈ μ‘μ„±
3. ν† ν¬λ‚μ΄μ € ν…μ¤νΈ
4. λ°μ΄ν„°μ…‹ ν΄λμ¤ κµ¬ν„

**μ‚°μ¶λ¬Ό**:
- `data/prepare_dataset.py`
- `src/dataset.py`
- μ „μ²λ¦¬λ λ°μ΄ν„° μƒν”

---

### Phase 3: λ¨λΈ λ° LoRA μ„¤μ • (45λ¶„)
1. λ¨λΈ λ΅λ”© ν•¨μ κµ¬ν„ (4-bit μ–‘μν™”)
2. LoRA μ„¤μ • μ μ©
3. λ¨λΈ λ©”λ¨λ¦¬ μ‚¬μ©λ‰ ν™•μΈ
4. κ°„λ‹¨ν• μ¶”λ΅  ν…μ¤νΈ

**μ‚°μ¶λ¬Ό**:
- `src/model.py`
- `src/utils.py`
- λ¨λΈ λ΅λ”© κ²€μ¦ μ¤ν¬λ¦½νΈ

---

### Phase 4: ν•™μµ νμ΄ν”„λΌμΈ κµ¬ν„ (1μ‹κ°„)
1. Trainer ν΄λμ¤ κµ¬ν„
2. ν•™μµ λ£¨ν”„ μ‘μ„±
3. μ²΄ν¬ν¬μΈνΈ μ €μ¥ λ΅μ§
4. λ΅κΉ… λ° λ¨λ‹ν„°λ§ μ„¤μ •

**μ‚°μ¶λ¬Ό**:
- `src/trainer.py`
- `scripts/train.py`
- ν•™μµ λ΅κ·Έ μμ‹

---

### Phase 5: μ¶”λ΅  λ° ν‰κ°€ (30λ¶„)
1. μ¶”λ΅  μ¤ν¬λ¦½νΈ μ‘μ„±
2. LoRA κ°€μ¤‘μΉ λ³‘ν•© μ¤ν¬λ¦½νΈ
3. κ°„λ‹¨ν• ν‰κ°€ λ©”νΈλ¦­ κµ¬ν„
4. λ°λ¨ λ…ΈνΈλ¶ μ‘μ„±

**μ‚°μ¶λ¬Ό**:
- `scripts/inference.py`
- `scripts/merge_lora.py`
- `notebooks/demo.ipynb`

---

### Phase 6: ν…μ¤νΈ λ° μµμ ν™” (30λ¶„)
1. μ „μ²΄ νμ΄ν”„λΌμΈ ν…μ¤νΈ
2. VRAM μ‚¬μ©λ‰ λ¨λ‹ν„°λ§
3. ν•μ΄νΌνλΌλ―Έν„° νλ‹
4. λ¬Έμ„ν™” μ™„μ„±

**μ‚°μ¶λ¬Ό**:
- `README.md`
- `tests/test_model.py`
- μµμΆ… ν•™μµ κ²°κ³Ό λ¦¬ν¬νΈ

---

## π“ μμƒ ν•™μµ μ‹κ°„ λ° μ„±λ¥

### ν•™μµ μ‹κ°„ (Phi-2 κΈ°μ¤€)
- **λ°μ΄ν„°μ…‹ ν¬κΈ°**: 10,000 μƒν”
- **Epoch**: 3
- **μμƒ μ‹κ°„**: 2-3μ‹κ°„ (RTX 3070)
- **μ²΄ν¬ν¬μΈνΈ ν¬κΈ°**: ~10-20MB (LoRA μ–΄λ‘ν„°λ§)

### λ©”λ¨λ¦¬ μ‚¬μ©λ‰
- **λ¨λΈ λ΅λ”©**: ~3-4GB (4-bit μ–‘μν™”)
- **ν•™μµ μ¤‘**: ~6-7GB (Gradient Checkpointing ν¬ν•¨)
- **μ—¬μ  λ©”λ¨λ¦¬**: ~1-2GB

---

## π€ μ‹¤ν–‰ μμ‹

### 1. ν™κ²½ μ„¤μ •
```bash
# κ°€μƒν™κ²½ μƒμ„±
python -m venv venv
source venv/bin/activate  # Linux/Mac
# venv\Scripts\activate  # Windows

# ν¨ν‚¤μ§€ μ„¤μΉ
pip install -r requirements.txt
```

### 2. λ°μ΄ν„° μ¤€λΉ„
```bash
python data/prepare_dataset.py --dataset koalpaca --num_samples 10000
```

### 3. ν•™μµ μ‹¤ν–‰
```bash
python scripts/train.py \
    --model_name microsoft/phi-2 \
    --dataset_path data/processed/train.json \
    --output_dir outputs/checkpoints \
    --num_epochs 3 \
    --batch_size 1 \
    --gradient_accumulation_steps 16
```

### 4. μ¶”λ΅  ν…μ¤νΈ
```bash
python scripts/inference.py \
    --base_model microsoft/phi-2 \
    --lora_weights outputs/checkpoints/final \
    --prompt "ν•κµ­μ μλ„λ” μ–΄λ””μΈκ°€μ”?"
```

### 5. LoRA κ°€μ¤‘μΉ λ³‘ν•©
```bash
python scripts/merge_lora.py \
    --base_model microsoft/phi-2 \
    --lora_weights outputs/checkpoints/final \
    --output_dir outputs/merged_models/phi2-lora-merged
```

---

## π“ λ¨λ‹ν„°λ§ λ° λ””λ²„κΉ…

### VRAM λ¨λ‹ν„°λ§
```bash
# μ‹¤μ‹κ°„ GPU μ‚¬μ©λ‰ ν™•μΈ
watch -n 1 nvidia-smi
```

### ν•™μµ λ΅κ·Έ ν™•μΈ
- TensorBoard λλ” Weights & Biases μ‚¬μ©
- μ†μ‹¤(Loss) κ°μ† μ¶”μ΄ ν™•μΈ
- Gradient Norm λ¨λ‹ν„°λ§

### μΌλ°μ μΈ λ¬Έμ  ν•΄κ²°
1. **OOM (Out of Memory)**:
   - `batch_size` κ°μ†
   - `max_seq_length` κ°μ†
   - `gradient_accumulation_steps` μ¦κ°€
   - `lora_r` κ°μ†

2. **ν•™μµ λ¶μ•μ •**:
   - Learning rate κ°μ†
   - Warmup steps μ¦κ°€
   - Gradient clipping μ μ©

3. **μ„±λ¥ λ¶€μ΅±**:
   - λ” λ§μ€ λ°μ΄ν„° μ‚¬μ©
   - Epoch μ μ¦κ°€
   - `lora_r` μ¦κ°€ (λ©”λ¨λ¦¬ ν—μ© λ²”μ„ λ‚΄)

---

## π― μ„±κ³µ κΈ°μ¤€

### μµμ† λ©ν‘
- [x] 8GB VRAM λ‚΄μ—μ„ ν•™μµ μ™„λ£
- [x] LoRA μ–΄λ‘ν„° μ €μ¥ λ° λ΅λ”© μ„±κ³µ
- [x] κΈ°λ³Έμ μΈ μ¶”λ΅  λ™μ‘ ν™•μΈ

### κ¶μ¥ λ©ν‘
- [x] ν•™μµ μ†μ‹¤(Loss) μ§€μ†μ  κ°μ†
- [x] μ¶”λ΅  ν’μ§ ν–¥μƒ ν™•μΈ
- [x] μ²΄ν¬ν¬μΈνΈ κ΄€λ¦¬ λ° μ¬κ° κ°€λ¥

### κ³ κΈ‰ λ©ν‘
- [x] λ‹¤μ–‘ν• ν”„λ΅¬ν”„νΈμ—μ„ μΌκ΄€λ μ„±λ¥
- [x] λ³‘ν•©λ λ¨λΈ λ°°ν¬ κ°€λ¥
- [x] ν•μ΄νΌνλΌλ―Έν„° μµμ ν™” μ™„λ£

---

## π“– μ°Έκ³  μλ£

1. **LoRA λ…Όλ¬Έ**: [LoRA: Low-Rank Adaptation of Large Language Models](https://arxiv.org/abs/2106.09685)
2. **QLoRA λ…Όλ¬Έ**: [QLoRA: Efficient Finetuning of Quantized LLMs](https://arxiv.org/abs/2305.14314)
3. **Hugging Face PEFT**: https://github.com/huggingface/peft
4. **Phi-2 λ¨λΈ**: https://huggingface.co/microsoft/phi-2
5. **KoAlpaca λ°μ΄ν„°μ…‹**: https://github.com/Beomi/KoAlpaca

---

## π’΅ λ‹¤μ λ‹¨κ³„

μ΄ μ„¤κ³„μ•μ„ κ²€ν† ν•μ‹  ν›„, λ‹¤μκ³Ό κ°™μ΄ μ§„ν–‰ν•κ² μµλ‹λ‹¤:

1. **Phase 1λ¶€ν„° μμ°¨μ μΌλ΅ κµ¬ν„** μ‹μ‘
2. κ° Phaseλ³„λ΅ μ½”λ“ μ‘μ„± λ° ν…μ¤νΈ
3. λ¬Έμ  λ°μƒ μ‹ μ¦‰μ‹ λ””λ²„κΉ… λ° μµμ ν™”
4. μµμΆ…μ μΌλ΅ μ™„μ „ν λ™μ‘ν•λ” λ°λ¨ ν”„λ΅μ νΈ μ™„μ„±

**μ§λ¬Έμ‚¬ν•­**:
- νΉμ • λ„λ©”μΈμ΄λ‚ μ‘μ—…μ— μ§‘μ¤‘ν•κ³  μ‹¶μΌμ‹ κ°€μ”? (μ: μ±—λ΄‡, μ”μ•½, QA λ“±)
- λ°μ΄ν„°μ…‹μ€ κ³µκ° λ°μ΄ν„°μ…‹μ„ μ‚¬μ©ν•μ‹κ² μµλ‹κΉ, μ•„λ‹λ©΄ μ»¤μ¤ν…€ λ°μ΄ν„°λ¥Ό μ¤€λΉ„ν•μ‹κ² μµλ‹κΉ?
- Wandb κ°™μ€ μ‹¤ν— μ¶”μ  λ„κµ¬λ¥Ό μ‚¬μ©ν•μ‹κ² μµλ‹κΉ?

μ¤€λΉ„λμ‹λ©΄ Phase 1λ¶€ν„° μ½”λ“ μ‘μ„±μ„ μ‹μ‘ν•κ² μµλ‹λ‹¤! π€
